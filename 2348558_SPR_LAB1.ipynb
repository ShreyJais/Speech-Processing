{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyJais/Speech-Processing/blob/main/2348558_SPR_LAB1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1- Implement sampling and quantization techniques for the given speech signals."
      ],
      "metadata": {
        "id": "qJIRP_8V7sgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (a) Plot the time domain representation of the original speech signal."
      ],
      "metadata": {
        "id": "pCUTydFM7v97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "amplitude,sample_rate = librosa.load('/content/audio.mp3',sr=None) #sr(sample rate)"
      ],
      "metadata": {
        "id": "CqVc9EPI_26x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.line(y=amplitude, title='Audio Waveform')\n",
        "fig.update_xaxes(title_text='Time')\n",
        "fig.update_yaxes(title_text='Amplitude')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_BOrSWhY9oph",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Current Sample Rate:\",sample_rate)"
      ],
      "metadata": {
        "id": "zX8ZVV-KBRqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (b) Sample the speech signal at different sampling rates (e.g., 8kHz, 16kHz, and 44.1kHz)."
      ],
      "metadata": {
        "id": "eYWeLVAk71_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resample1=librosa.resample(amplitude,orig_sr=sample_rate,target_sr=8000)\n",
        "resample2=librosa.resample(amplitude,orig_sr=sample_rate,target_sr=16000)\n",
        "resample3=librosa.resample(amplitude,orig_sr=sample_rate,target_sr=44100)"
      ],
      "metadata": {
        "id": "DiWQrQ1gBaCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = px.line(y=resample1, title='Resampled Audio (8kHz)')\n",
        "fig1.update_xaxes(title_text='Time')\n",
        "fig1.update_yaxes(title_text='Amplitude')\n",
        "\n",
        "fig2 = px.line(y=resample2, title='Resampled Audio (16kHz)')\n",
        "fig2.update_xaxes(title_text='Time')\n",
        "fig2.update_yaxes(title_text='Amplitude')\n",
        "\n",
        "fig3 = px.line(y=resample3, title='Resampled Audio (44.1kHz)')\n",
        "fig3.update_xaxes(title_text='Time')\n",
        "fig3.update_yaxes(title_text='Amplitude')\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()\n",
        "fig3.show()"
      ],
      "metadata": {
        "id": "CKaoTJRM-bV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (d) Using the sampled signals from the above task, reconstruct the signal using:\n",
        "#### (i) Zero-order hold (nearest-neighbor interpolation)\n",
        "####Â (ii) Linear interpolation."
      ],
      "metadata": {
        "id": "q8SZ2moW8Fm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import interpolate\n",
        "import numpy as np\n",
        "interpolation1=interpolate.interp1d([x for x in range(len(resample1))],resample1,kind='zero')\n",
        "interpolation2=interpolate.interp1d([x for x in range(len(resample1))],resample1,kind='linear')\n",
        "interpolation3=interpolate.interp1d([x for x in range(len(resample2))],resample2,kind='zero')\n",
        "interpolation4=interpolate.interp1d([x for x in range(len(resample2))],resample2,kind='linear')\n",
        "new=np.linspace(0,len(resample1)-1,len(amplitude))\n",
        "upsample8a=interpolation1(new)\n",
        "upsample8b=interpolation2(new)\n",
        "upsample16a=interpolation3(new)\n",
        "upsample16b=interpolation4(new)"
      ],
      "metadata": {
        "id": "JWGIFROyC9IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (e) Calculate the Mean Squared Error (MSE) between the original and the reconstructed signals for both methods."
      ],
      "metadata": {
        "id": "Xud5SsjmuQXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Mean square error post reconstructing 8KHz using zero-hold interpolation: \",mean_squared_error(amplitude,upsample8a))\n",
        "print(\"Mean square error post reconstructing 8KHz using Linear interpolation: \",mean_squared_error(amplitude,upsample8b))\n",
        "print(\"Mean square error post reconstructing 16KHz using zero-hold interpolation: \",mean_squared_error(amplitude,upsample16a))\n",
        "print(\"Mean square error post reconstructing 16KHz using Linear interpolation: \",mean_squared_error(amplitude,upsample16b))"
      ],
      "metadata": {
        "id": "hMf3InvIC_rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2- Implement the source-filter Model for a given speech signal and analyze the impact of sampling and reconstruction on the quality of the speech signal."
      ],
      "metadata": {
        "id": "aH3uzOeH8eO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (a) Generate a synthetic speech signal using the source-filter model.\n",
        "#### (i) Create a source signal (e.g., a glottal pulse train for voiced sounds or white noise for unvoiced sounds).\n",
        "#### (ii) Apply a filter that models the vocal tract, represented by an all-pole filter or an FIR filter with formants (resonances of the vocal tract)."
      ],
      "metadata": {
        "id": "jLP9c1nh8fTR"
      }
    },
    {
      "source": [
        "time = np.linspace(0, 1, 1000)\n",
        "frequency = 3\n",
        "continuous_signal = np.sin(2 * np.pi * frequency * time)\n",
        "\n",
        "fig = px.line(x=time, y=continuous_signal, title='Continuous Signal')\n",
        "fig.update_xaxes(title_text='Time')\n",
        "fig.update_yaxes(title_text='Amplitude')\n",
        "fig.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "z0F5y5ep-pS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "noise_signal = np.random.randn(1000)\n",
        "\n",
        "fig = px.line(y=noise_signal, title='Noise Signal')\n",
        "fig.update_xaxes(title_text='Time')\n",
        "fig.update_yaxes(title_text='Amplitude')\n",
        "fig.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "-4CtC_pP-uq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "signal = continuous_signal + noise_signal\n",
        "\n",
        "fig = px.line(y=signal, title='Combined Signal')\n",
        "fig.update_xaxes(title_text='Time')\n",
        "fig.update_yaxes(title_text='Amplitude')\n",
        "fig.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VtDQKeBN-1BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import firwin, lfilter\n",
        "numtaps=101\n",
        "formant_frequencies=[500, 1500, 2500]\n",
        "normalized_freqs=[f/(240000/2) for f in formant_frequencies]\n",
        "vocal_tract_filter=firwin(numtaps,normalized_freqs,pass_zero=False)"
      ],
      "metadata": {
        "id": "jMvKkZ337T5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (b) Plot the generated speech signal and analyze the effect of the filter on the original source."
      ],
      "metadata": {
        "id": "5EbM2Ws78kCu"
      }
    },
    {
      "source": [
        "filtered_glottal_pulse = lfilter(vocal_tract_filter, 1.0, continuous_signal)\n",
        "\n",
        "fig1 = px.line(y=continuous_signal, title='Original Continuous Signal')\n",
        "fig1.update_xaxes(title_text='Time')\n",
        "fig1.update_yaxes(title_text='Amplitude')\n",
        "\n",
        "fig2 = px.line(y=filtered_glottal_pulse[:1000], title='Filtered Glottal Pulse (Vocal Tract Filter Applied)')\n",
        "fig2.update_xaxes(title_text='Time')\n",
        "fig2.update_yaxes(title_text='Amplitude')\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1VG_wKKK_Lky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (c) Sample the speech signal generated in the above task at different sampling rates (e.g., 8 kHz, 16 kHz, 44.1 kHz)."
      ],
      "metadata": {
        "id": "vSyXMKa_8nKG"
      }
    },
    {
      "source": [
        "resampled_signals = [librosa.resample(filtered_glottal_pulse, orig_sr=24000, target_sr=rate) for rate in [8000, 16000, 44100]]\n",
        "\n",
        "for i, signal in enumerate(resampled_signals):\n",
        "    fig = px.line(y=signal[:1000], title=f'Sampled Speech Signal at {[8000, 16000, 44100][i]} Hz')\n",
        "    fig.update_xaxes(title_text='Time')\n",
        "    fig.update_yaxes(title_text='Amplitude')\n",
        "    fig.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gf2gvnTg_U8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (d) Reconstruct the signal using a suitable interpolation method (e.g., zero-order hold, linear interpolation).\n",
        "#### (e) Compute the Mean Squared Error (MSE) between the original and reconstructed speech signals."
      ],
      "metadata": {
        "id": "N1G9geB88qup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import interpolate\n",
        "for i in resampled_signals:\n",
        "    x = np.arange(len(i))\n",
        "    f_zero_order = interpolate.interp1d(x, i, kind='nearest')\n",
        "    f_linear = interpolate.interp1d(x, i, kind='linear')\n",
        "    x_new = np.linspace(0, len(i)-1, len(filtered_glottal_pulse))\n",
        "    reconstructed_zero_order = f_zero_order(x_new)\n",
        "    reconstructed_linear = f_linear(x_new)\n",
        "    mse_zero_order = mean_squared_error(filtered_glottal_pulse[:len(reconstructed_zero_order)], reconstructed_zero_order)\n",
        "    mse_linear = mean_squared_error(filtered_glottal_pulse[:len(reconstructed_linear)], reconstructed_linear)\n",
        "    print(f'MSE for Zero-Order Hold: {mse_zero_order}')\n",
        "    print(f'MSE for Linear Interpolation: {mse_linear}')"
      ],
      "metadata": {
        "id": "mJvvOIId7YLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "fig = px.line(y=filtered_glottal_pulse[:1000], title='Original Filtered Speech Signal (Source-Filter Model)')\n",
        "fig.update_xaxes(title_text='Time')\n",
        "fig.update_yaxes(title_text='Amplitude')\n",
        "fig.show()\n",
        "\n",
        "fig1 = px.line(y=reconstructed_zero_order[:1000], title='Reconstructed Speech Signal (Zero-Order Hold)')\n",
        "fig1.update_xaxes(title_text='Time')\n",
        "fig1.update_yaxes(title_text='Amplitude')\n",
        "fig1.show()\n",
        "\n",
        "fig2 = px.line(y=reconstructed_linear[:1000], title='Reconstructed Speech Signal (Linear Interpolation)')\n",
        "fig2.update_xaxes(title_text='Time')\n",
        "fig2.update_yaxes(title_text='Amplitude')\n",
        "fig2.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "lUCTJAn8_gAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HOyPPljx7bYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}